{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NhDp2UnLvju7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import io\n",
        "import imageio\n",
        "from IPython.display import Image, display\n",
        "from ipywidgets import widgets, Layout, HBox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F0O26XB32KyS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Dense, Dropout,Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "Accident_x = np.load('feature_maps/Acident_Data.npy')\n",
        "Accident_y = np.ones((50,1))\n",
        "\n",
        "NonAccident_x = np.load('feature_maps/Non-Acident_Data.npy')\n",
        "NonAccident_y = np.zeros((50,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the accident feature maps : (50, 45, 8, 8, 2048)\n",
            "The shape of the accident labels : (50, 1)\n",
            "The shape of the non-accident feature maps : (50, 45, 8, 8, 2048)\n",
            "The shape of the non-accident labels : (50, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"The shape of the accident feature maps :\",Accident_x.shape)\n",
        "print(\"The shape of the accident labels :\",Accident_y.shape)\n",
        "print(\"The shape of the non-accident feature maps :\",NonAccident_x.shape)\n",
        "print(\"The shape of the non-accident labels :\",NonAccident_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the all feature maps : (100, 45, 8, 8, 2048)\n",
            "The shape of the all labels : (100, 1)\n"
          ]
        }
      ],
      "source": [
        "Data_x = np.vstack((Accident_x, NonAccident_x))\n",
        "Data_y = np.vstack((Accident_y, NonAccident_y))\n",
        "\n",
        "print(\"The shape of the all feature maps :\",Data_x.shape)\n",
        "print(\"The shape of the all labels :\",Data_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the all feature maps : (100, 45, 8, 8, 2048)\n",
            "The shape of the all labels : (100, 1)\n"
          ]
        }
      ],
      "source": [
        "indices = np.random.permutation(Data_x.shape[0])\n",
        "\n",
        "shuffled_Data_x = Data_x[indices]\n",
        "shuffled_Data_y = Data_y[indices]\n",
        "\n",
        "print(\"The shape of the all feature maps :\",shuffled_Data_x.shape)\n",
        "print(\"The shape of the all labels :\",shuffled_Data_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of training data : (90, 45, 8, 8, 2048)\n",
            "The shape of validation data : (10, 45, 8, 8, 2048)\n",
            "The shape of training labels : (90, 1)\n",
            "The shape of validation labels : (10, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_val = np.split(shuffled_Data_x, [90], axis=0)\n",
        "y_train, y_val = np.split(shuffled_Data_y, [90], axis=0)\n",
        "\n",
        "x_train = x_train.astype(np.float16)\n",
        "x_val = x_val.astype(np.float16)\n",
        "y_train = y_train.astype(np.float16)\n",
        "y_val = y_val.astype(np.float16)\n",
        "\n",
        "print(\"The shape of training data :\",x_train.shape)\n",
        "print(\"The shape of validation data :\",x_val.shape)\n",
        "print(\"The shape of training labels :\",y_train.shape)\n",
        "print(\"The shape of validation labels :\",y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('DATA/X_train.npy', x_train)\n",
        "np.save('DATA/X_val.npy', x_val)\n",
        "np.save('DATA/y_train.npy', y_train)\n",
        "np.save('DATA/y_val_train.npy', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = np.load(\"DATA/X_train.npy\")\n",
        "x_val = np.load(\"DATA/X_val.npy.npy\")\n",
        "y_train = np.load(\"DATA/y_train.npy.npy\")\n",
        "y_val = np.load(\"DATA/X_val.npy.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga14ZU2u2SBB",
        "outputId": "eb70635f-5874-42a5-9827-d3ab399fa22f"
      },
      "outputs": [
        {
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__StatelessRandomGetKeyCounter_device_/job:localhost/replica:0/task:0/device:GPU:0}} SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;d3a99ff7edf1a7fa;/job:localhost/replica:0/task:0/device:GPU:0;edge_3_StatelessRandomGetKeyCounter;0:0\n\t [[{{node StatelessRandomGetKeyCounter/_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:StatelessRandomGetKeyCounter]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      7\u001b[0m \u001b[39m\"\"\"model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True, input_shape=input_shape))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39mmodel.add(BatchNormalization())\"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model\u001b[39m.\u001b[39;49madd(ConvLSTM2D(filters\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49minput_shape))\n\u001b[0;32m     13\u001b[0m model\u001b[39m.\u001b[39madd(BatchNormalization())\n\u001b[0;32m     15\u001b[0m model\u001b[39m.\u001b[39madd(Flatten())\n",
            "File \u001b[1;32mc:\\Users\\Nour\\anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[0;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[0;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[0;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   2106\u001b[0m     )\n\u001b[0;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomGetKeyCounter_device_/job:localhost/replica:0/task:0/device:GPU:0}} SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:GPU:0;d3a99ff7edf1a7fa;/job:localhost/replica:0/task:0/device:GPU:0;edge_3_StatelessRandomGetKeyCounter;0:0\n\t [[{{node StatelessRandomGetKeyCounter/_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:StatelessRandomGetKeyCounter]"
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "input_shape = (None,  8, 8,2048)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\"\"\"model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True, input_shape=input_shape))\n",
        "\n",
        "model.add(BatchNormalization())\"\"\"\n",
        "\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=False, input_shape=input_shape))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\"\"\"model.add(Dense(400))\n",
        "model.add(Dropout(0.3))\"\"\"\n",
        "\n",
        "\"\"\"model.add(Dense(100))\n",
        "model.add(Dropout(0.3))\"\"\"\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0OmB1F0E2W0T"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a3seArg1bub4"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEWSRCWJXtUW",
        "outputId": "408c990a-033b-4900-a546-d42338e0e114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 959, in _create_all_weights\n        self._create_slots(var_list)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 126, in _create_slots\n        self.add_slot(var, \"m\")\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 1050, in add_slot\n        weight = tf.Variable(\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\", line 171, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train,y_train,validation_data\u001b[39m=\u001b[39;49m (x_val,y_val) , epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Nour\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1233\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1234\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 959, in _create_all_weights\n        self._create_slots(var_list)\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 126, in _create_slots\n        self.add_slot(var, \"m\")\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 1050, in add_slot\n        weight = tf.Variable(\n    File \"c:\\Users\\Nour\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\", line 171, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train,y_train,validation_data= (x_val,y_val) , epochs=10,batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-hpZUFRcT7J",
        "outputId": "c92e7a8e-be34-4fc7-8212-0abdc6761ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpEwCFu_x4rX",
        "outputId": "5bbe4746-d24e-4985-f644-28f45bcaf8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
